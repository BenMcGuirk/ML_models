{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Linear regression from scratch","metadata":{}},{"cell_type":"markdown","source":"## Firstly ignoring category data (dropping)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-24T13:44:41.246739Z","iopub.execute_input":"2024-09-24T13:44:41.247180Z","iopub.status.idle":"2024-09-24T13:44:41.670245Z","shell.execute_reply.started":"2024-09-24T13:44:41.247129Z","shell.execute_reply":"2024-09-24T13:44:41.668972Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Preprocess train set","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\n\n# Drop categorical features\ncategorical_columns = train.select_dtypes(include=['category', 'object']).columns\ntrain.drop(columns=categorical_columns, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:44:53.529700Z","iopub.execute_input":"2024-09-24T13:44:53.530439Z","iopub.status.idle":"2024-09-24T13:44:53.592675Z","shell.execute_reply.started":"2024-09-24T13:44:53.530380Z","shell.execute_reply":"2024-09-24T13:44:53.591442Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Identify features with missing values (nan)\nmissing_values = train.isnull().sum()\n\n# Filter to show only columns with missing values\nmissing_values = missing_values[missing_values > 0]\n\nprint(\"Columns with missing values:\")\nprint(missing_values)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:44:55.419160Z","iopub.execute_input":"2024-09-24T13:44:55.419729Z","iopub.status.idle":"2024-09-24T13:44:55.431599Z","shell.execute_reply.started":"2024-09-24T13:44:55.419671Z","shell.execute_reply":"2024-09-24T13:44:55.430170Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Columns with missing values:\nLotFrontage    259\nMasVnrArea       8\nGarageYrBlt     81\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In this case, we want all categories with missing values to be imputed with 0.","metadata":{}},{"cell_type":"code","source":"# Replace both string 'nan' and NaN values with 0 for zero features\ntrain = train.replace('nan', np.nan).fillna(0).astype('int64')\n\n# Assign SalePrice to Y_train and drop SalePrice and Id from X_train\ny_train = train[\"SalePrice\"]\nX_train = train.drop([\"SalePrice\", \"Id\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:44:57.803104Z","iopub.execute_input":"2024-09-24T13:44:57.804268Z","iopub.status.idle":"2024-09-24T13:44:57.814088Z","shell.execute_reply.started":"2024-09-24T13:44:57.804205Z","shell.execute_reply":"2024-09-24T13:44:57.812907Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Check that all data types match\n#print(X_train.dtypes)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T10:47:59.693847Z","iopub.execute_input":"2024-09-15T10:47:59.694321Z","iopub.status.idle":"2024-09-15T10:47:59.699772Z","shell.execute_reply.started":"2024-09-15T10:47:59.694279Z","shell.execute_reply":"2024-09-15T10:47:59.698230Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Preprocess test set","metadata":{}},{"cell_type":"code","source":"X_test = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n\n# Drop categorical features\ncategorical_columns = X_test.select_dtypes(include=['category', 'object']).columns\nX_test.drop(columns=categorical_columns, inplace=True)\n\nX_test = X_test.drop([\"Id\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:45:01.672772Z","iopub.execute_input":"2024-09-24T13:45:01.673208Z","iopub.status.idle":"2024-09-24T13:45:01.716590Z","shell.execute_reply.started":"2024-09-24T13:45:01.673166Z","shell.execute_reply":"2024-09-24T13:45:01.715387Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Identify features with missing values (nan)\nmissing_values = X_test.isnull().sum()\n\n# Filter to show only columns with missing values\nmissing_values = missing_values[missing_values > 0]\n\nprint(\"Columns with missing values:\")\nprint(missing_values)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:45:03.620837Z","iopub.execute_input":"2024-09-24T13:45:03.621710Z","iopub.status.idle":"2024-09-24T13:45:03.629356Z","shell.execute_reply.started":"2024-09-24T13:45:03.621653Z","shell.execute_reply":"2024-09-24T13:45:03.628281Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Columns with missing values:\nLotFrontage     227\nMasVnrArea       15\nBsmtFinSF1        1\nBsmtFinSF2        1\nBsmtUnfSF         1\nTotalBsmtSF       1\nBsmtFullBath      2\nBsmtHalfBath      2\nGarageYrBlt      78\nGarageCars        1\nGarageArea        1\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Replace both string 'nan' and NaN values with 0 for zero features\nX_test = X_test.replace('nan', np.nan).fillna(0).astype('int64')","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:45:06.378849Z","iopub.execute_input":"2024-09-24T13:45:06.379274Z","iopub.status.idle":"2024-09-24T13:45:06.386268Z","shell.execute_reply.started":"2024-09-24T13:45:06.379231Z","shell.execute_reply":"2024-09-24T13:45:06.385178Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Check that all data types match\n#print(X_test.dtypes)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T11:15:20.750551Z","iopub.execute_input":"2024-09-15T11:15:20.750955Z","iopub.status.idle":"2024-09-15T11:15:20.755823Z","shell.execute_reply.started":"2024-09-15T11:15:20.750918Z","shell.execute_reply":"2024-09-15T11:15:20.754687Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Feature scaling","metadata":{}},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:45:10.712845Z","iopub.execute_input":"2024-09-24T13:45:10.713301Z","iopub.status.idle":"2024-09-24T13:45:10.738261Z","shell.execute_reply.started":"2024-09-24T13:45:10.713257Z","shell.execute_reply":"2024-09-24T13:45:10.737068Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n0          60           65     8450            7            5       2003   \n1          20           80     9600            6            8       1976   \n2          60           68    11250            7            5       2001   \n3          70           60     9550            7            5       1915   \n4          60           84    14260            8            5       2000   \n\n   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageArea  \\\n0          2003         196         706           0  ...         548   \n1          1976           0         978           0  ...         460   \n2          2002         162         486           0  ...         608   \n3          1970           0         216           0  ...         642   \n4          2000         350         655           0  ...         836   \n\n   WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  \\\n0           0           61              0          0            0         0   \n1         298            0              0          0            0         0   \n2           0           42              0          0            0         0   \n3           0           35            272          0            0         0   \n4         192           84              0          0            0         0   \n\n   MiscVal  MoSold  YrSold  \n0        0       2    2008  \n1        0       5    2007  \n2        0       9    2008  \n3        0       2    2006  \n4        0      12    2008  \n\n[5 rows x 36 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinSF2</th>\n      <th>...</th>\n      <th>GarageArea</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60</td>\n      <td>65</td>\n      <td>8450</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>196</td>\n      <td>706</td>\n      <td>0</td>\n      <td>...</td>\n      <td>548</td>\n      <td>0</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>80</td>\n      <td>9600</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>0</td>\n      <td>978</td>\n      <td>0</td>\n      <td>...</td>\n      <td>460</td>\n      <td>298</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>68</td>\n      <td>11250</td>\n      <td>7</td>\n      <td>5</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>162</td>\n      <td>486</td>\n      <td>0</td>\n      <td>...</td>\n      <td>608</td>\n      <td>0</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>60</td>\n      <td>9550</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1915</td>\n      <td>1970</td>\n      <td>0</td>\n      <td>216</td>\n      <td>0</td>\n      <td>...</td>\n      <td>642</td>\n      <td>0</td>\n      <td>35</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>84</td>\n      <td>14260</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2000</td>\n      <td>2000</td>\n      <td>350</td>\n      <td>655</td>\n      <td>0</td>\n      <td>...</td>\n      <td>836</td>\n      <td>192</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 36 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Initialize the StandardScaler\nscaler = StandardScaler()\n\n# Fit the scaler on the training data\nscaler.fit(X_train)\n\n# Transform both training and test data\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:45:13.465034Z","iopub.execute_input":"2024-09-24T13:45:13.465462Z","iopub.status.idle":"2024-09-24T13:45:14.000050Z","shell.execute_reply.started":"2024-09-24T13:45:13.465422Z","shell.execute_reply":"2024-09-24T13:45:13.998725Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"y_train.head(1)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:45:16.152728Z","iopub.execute_input":"2024-09-24T13:45:16.153312Z","iopub.status.idle":"2024-09-24T13:45:16.161828Z","shell.execute_reply.started":"2024-09-24T13:45:16.153269Z","shell.execute_reply":"2024-09-24T13:45:16.160679Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0    208500\nName: SalePrice, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"y_scaler = StandardScaler()\ny_train_2d = np.array(y_train).reshape(-1, 1)\ny_train = y_scaler.fit_transform(y_train_2d)\ny_train = y_train.flatten()","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:45:19.936786Z","iopub.execute_input":"2024-09-24T13:45:19.937794Z","iopub.status.idle":"2024-09-24T13:45:19.946045Z","shell.execute_reply.started":"2024-09-24T13:45:19.937734Z","shell.execute_reply":"2024-09-24T13:45:19.944565Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"y_train[0]","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:45:21.999404Z","iopub.execute_input":"2024-09-24T13:45:21.999850Z","iopub.status.idle":"2024-09-24T13:45:22.007585Z","shell.execute_reply.started":"2024-09-24T13:45:21.999807Z","shell.execute_reply":"2024-09-24T13:45:22.006142Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0.34727321973650555"},"metadata":{}}]},{"cell_type":"code","source":"class LinearRegression:\n    def __init__(self, learning_rate=0.01, n_iterations=1000):\n        self.learning_rate = learning_rate\n        self.n_iterations = n_iterations\n        self.weights = None\n        self.bias = None\n\n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n        \n        # Initialize weights and bias\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n\n        # Gradient descent\n        for i in range(self.n_iterations):\n            y_predicted = np.dot(X, self.weights) + self.bias\n\n            # Compute gradients\n            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n            db = (1 / n_samples) * np.sum(y_predicted - y)\n\n            # Update parameters\n            self.weights -= self.learning_rate * dw\n            self.bias -= self.learning_rate * db\n            \n            # Print loss every 100th iteration\n            if i % 100 == 0:\n                n = len(y)\n                loss = (1/n) * sum((y - y_predicted)**2)\n                print(f\"Iteration {i}: Loss = {loss}\")\n\n    def predict(self, X):\n        return np.dot(X, self.weights) + self.bias","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:45:26.271015Z","iopub.execute_input":"2024-09-24T13:45:26.271454Z","iopub.status.idle":"2024-09-24T13:45:26.281614Z","shell.execute_reply.started":"2024-09-24T13:45:26.271412Z","shell.execute_reply":"2024-09-24T13:45:26.280345Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Assuming X_train and y_train are your training data\nmodel = LinearRegression(learning_rate=0.1, n_iterations=1000)\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred_scaled = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:45:33.705920Z","iopub.execute_input":"2024-09-24T13:45:33.706363Z","iopub.status.idle":"2024-09-24T13:45:33.779805Z","shell.execute_reply.started":"2024-09-24T13:45:33.706323Z","shell.execute_reply":"2024-09-24T13:45:33.778548Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Iteration 0: Loss = 1.000000000000002\nIteration 100: Loss = 0.18394708801130707\nIteration 200: Loss = 0.18363631820679843\nIteration 300: Loss = 0.18360703657299574\nIteration 400: Loss = 0.18360328781236682\nIteration 500: Loss = 0.1836027815305142\nIteration 600: Loss = 0.18360271184218835\nIteration 700: Loss = 0.18360270217370214\nIteration 800: Loss = 0.1836027008277\nIteration 900: Loss = 0.18360270064002768\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'y[0] pre-scaling: {y_pred_scaled[0]}')\n# Scale up y_pred (inverse transform)\ny_pred_2d = y_pred_scaled.reshape(-1, 1)\n\n# Now, use the scaler to inverse transform\ny_pred_original = y_scaler.inverse_transform(y_pred_2d)\n\n# If you need y_pred_original as a 1D array, flatten it\ny_pred_original = y_pred_original.flatten()\nprint(f'y[0] post-scaling: {y_pred_original[0]}')","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:45:43.311301Z","iopub.execute_input":"2024-09-24T13:45:43.311761Z","iopub.status.idle":"2024-09-24T13:45:43.319703Z","shell.execute_reply.started":"2024-09-24T13:45:43.311710Z","shell.execute_reply":"2024-09-24T13:45:43.318239Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"y[0] pre-scaling: -0.7732380604357663\ny[0] post-scaling: 119514.26962348787\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred_original","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:45:48.898850Z","iopub.execute_input":"2024-09-24T13:45:48.899755Z","iopub.status.idle":"2024-09-24T13:45:48.908007Z","shell.execute_reply.started":"2024-09-24T13:45:48.899681Z","shell.execute_reply":"2024-09-24T13:45:48.906943Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"array([119514.26962349, 152368.50461324, 172896.62593489, ...,\n       179828.18462177, 118988.40558454, 258064.6392571 ])"},"metadata":{}}]},{"cell_type":"markdown","source":"Submit predictions!","metadata":{}},{"cell_type":"code","source":"# Create a DataFrame for the submission\nsubmission = pd.DataFrame({\n    'Id': range(1461, 2920),  # Creates IDs from 1461 to 2919\n    'SalePrice': y_pred_original\n})\n\n# Ensure 'Id' is integer type\nsubmission['Id'] = submission['Id'].astype(int)\n\n# Save the DataFrame to a CSV file\nsubmission.to_csv('submission.csv', index=False)\n\n# Print the first few rows to verify\nprint(submission.head())\n\n# Print some information about the submission file\nprint(\"\\nSubmission file info:\")\nprint(f\"Number of predictions: {len(submission)}\")\nprint(f\"ID range: {submission['Id'].min()} to {submission['Id'].max()}\")\nprint(f\"SalePrice range: ${submission['SalePrice'].min():.2f} to ${submission['SalePrice'].max():.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-24T13:46:00.141520Z","iopub.execute_input":"2024-09-24T13:46:00.142397Z","iopub.status.idle":"2024-09-24T13:46:00.168496Z","shell.execute_reply.started":"2024-09-24T13:46:00.142337Z","shell.execute_reply":"2024-09-24T13:46:00.166959Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"     Id      SalePrice\n0  1461  119514.269623\n1  1462  152368.504613\n2  1463  172896.625935\n3  1464  200219.921394\n4  1465  194974.933609\n\nSubmission file info:\nNumber of predictions: 1459\nID range: 1461 to 2919\nSalePrice range: $340.96 to $633650.24\n","output_type":"stream"}]}]}