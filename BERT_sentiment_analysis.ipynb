{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Using pre trained BERT from hugging face + LRC head for fine tuning","metadata":{}},{"cell_type":"markdown","source":"## Task will be sentiment analysis of IMDB movie reviews","metadata":{}},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"!pip install transformers datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-16T08:54:03.239432Z","iopub.execute_input":"2024-10-16T08:54:03.239950Z","iopub.status.idle":"2024-10-16T08:54:20.487516Z","shell.execute_reply.started":"2024-10-16T08:54:03.239906Z","shell.execute_reply":"2024-10-16T08:54:20.485871Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\nds = load_dataset(\"stanfordnlp/imdb\")","metadata":{"execution":{"iopub.status.busy":"2024-10-16T12:37:11.601388Z","iopub.execute_input":"2024-10-16T12:37:11.601766Z","iopub.status.idle":"2024-10-16T12:37:17.975904Z","shell.execute_reply.started":"2024-10-16T12:37:11.601731Z","shell.execute_reply":"2024-10-16T12:37:17.975143Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c017baa79af94a20a0d9f22f9bdb9f29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e5715c17fe14f5cbfe1d359d306bd89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c16a598618df4e96bb37e100b0aa36c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0627ee1b66e1468bbdddeb225064a8cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76361cf95e9d4472940fc4a730d368f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dae215da1c74c8b95355b4afe7575a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a50e12363bbc4651a0f858d7424586ec"}},"metadata":{}}]},{"cell_type":"code","source":"print(ds)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T12:38:17.340321Z","iopub.execute_input":"2024-10-16T12:38:17.340952Z","iopub.status.idle":"2024-10-16T12:38:17.346481Z","shell.execute_reply.started":"2024-10-16T12:38:17.340913Z","shell.execute_reply":"2024-10-16T12:38:17.345414Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    unsupervised: Dataset({\n        features: ['text', 'label'],\n        num_rows: 50000\n    })\n})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T12:38:21.476960Z","iopub.execute_input":"2024-10-16T12:38:21.477401Z","iopub.status.idle":"2024-10-16T12:38:25.999721Z","shell.execute_reply.started":"2024-10-16T12:38:21.477361Z","shell.execute_reply":"2024-10-16T12:38:25.998481Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebb831190b3d41eebd285fefc08efd84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f7858b13f924e9f8645b7ba160da243"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"071d35e4fc514b82af53f18ca2cf5895"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f48feb1955e146029c92a5f72e7d5653"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d04368805bc841dd8596000a03ac7d4b"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T12:38:28.187553Z","iopub.execute_input":"2024-10-16T12:38:28.188156Z","iopub.status.idle":"2024-10-16T12:38:28.193054Z","shell.execute_reply.started":"2024-10-16T12:38:28.188115Z","shell.execute_reply":"2024-10-16T12:38:28.192055Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset = ds.map(tokenize_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T12:38:30.019580Z","iopub.execute_input":"2024-10-16T12:38:30.019971Z","iopub.status.idle":"2024-10-16T12:53:15.907880Z","shell.execute_reply.started":"2024-10-16T12:38:30.019934Z","shell.execute_reply":"2024-10-16T12:53:15.906873Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"624595fae02a4a4899585ceaa02e176b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f89fa07e99e493fbeb43d8c2ad08989"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a41a13e8e284b6691d88eb15c07836f"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_train = tokenized_dataset[\"train\"].remove_columns([\"text\"])\ntokenized_test = tokenized_dataset[\"test\"].remove_columns([\"text\"])","metadata":{"execution":{"iopub.status.busy":"2024-10-16T12:53:46.678028Z","iopub.execute_input":"2024-10-16T12:53:46.678953Z","iopub.status.idle":"2024-10-16T12:53:46.687928Z","shell.execute_reply.started":"2024-10-16T12:53:46.678915Z","shell.execute_reply":"2024-10-16T12:53:46.687024Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from transformers import BertModel, BertPreTrainedModel\nimport torch.nn as nn\n\nclass BertForSequenceClassification(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        self.num_labels = config.num_labels\n        self.bert = BertModel(config)\n        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n        self.init_weights()\n\n    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        pooled_output = outputs[1]\n        logits = self.classifier(pooled_output)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-10-16T12:53:49.525045Z","iopub.execute_input":"2024-10-16T12:53:49.525443Z","iopub.status.idle":"2024-10-16T12:53:49.965786Z","shell.execute_reply.started":"2024-10-16T12:53:49.525405Z","shell.execute_reply":"2024-10-16T12:53:49.964992Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from transformers import BertConfig\n\nconfig = BertConfig.from_pretrained('bert-base-uncased', num_labels=2)  # Assuming binary classification\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T12:53:52.452155Z","iopub.execute_input":"2024-10-16T12:53:52.452812Z","iopub.status.idle":"2024-10-16T12:53:54.162459Z","shell.execute_reply.started":"2024-10-16T12:53:52.452773Z","shell.execute_reply":"2024-10-16T12:53:54.161714Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec6abefbf4c94e6cba9652ce38bf6988"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Convert to tensors","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\nimport torch\n\ntrain_input_ids = tokenized_train[\"input_ids\"]\ntrain_attention_mask = tokenized_train[\"attention_mask\"]\ntrain_labels = tokenized_train[\"label\"]\n\ntest_input_ids = tokenized_test[\"input_ids\"]\ntest_attention_mask = tokenized_test[\"attention_mask\"]\ntest_labels = tokenized_test[\"label\"]\n\ntrain_dataset = TensorDataset(torch.tensor(train_input_ids),\n                              torch.tensor(train_attention_mask),\n                              torch.tensor(train_labels))\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\ntest_dataset = TensorDataset(torch.tensor(test_input_ids),\n                             torch.tensor(test_attention_mask),\n                             torch.tensor(test_labels))\ntest_dataloader = DataLoader(test_dataset, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T12:53:56.866850Z","iopub.execute_input":"2024-10-16T12:53:56.867262Z","iopub.status.idle":"2024-10-16T12:54:44.260358Z","shell.execute_reply.started":"2024-10-16T12:53:56.867224Z","shell.execute_reply":"2024-10-16T12:54:44.259506Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Load optimizer and loss function","metadata":{}},{"cell_type":"code","source":"from transformers import AdamW\n\noptimizer = AdamW(model.parameters(), lr=2e-5)\nloss_fn = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T12:54:54.248142Z","iopub.execute_input":"2024-10-16T12:54:54.249015Z","iopub.status.idle":"2024-10-16T12:54:55.324493Z","shell.execute_reply.started":"2024-10-16T12:54:54.248974Z","shell.execute_reply":"2024-10-16T12:54:55.323635Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Fine-tuning with labels","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nnum_epochs = 1\n\nfor epoch in range(num_epochs):\n    model.train()\n    for batch in train_dataloader:\n        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T12:55:00.255505Z","iopub.execute_input":"2024-10-16T12:55:00.256129Z","iopub.status.idle":"2024-10-16T13:31:07.692844Z","shell.execute_reply.started":"2024-10-16T12:55:00.256089Z","shell.execute_reply":"2024-10-16T13:31:07.691657Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nnum_epochs = 1\n\nfor epoch in range(num_epochs):\n    model.train()\n    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)\n    for batch in progress_bar:\n        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask=attention_mask)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        # Update progress bar description with current loss\n        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test model performance","metadata":{}},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\n\nmodel.eval()\n\nall_predictions = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in tqdm(test_dataloader, desc=\"Making predictions\"):\n        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n        \n        outputs = model(input_ids, attention_mask=attention_mask)\n        predictions = torch.argmax(outputs, dim=1)\n        \n        all_predictions.extend(predictions.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:40:53.438823Z","iopub.execute_input":"2024-10-16T13:40:53.439592Z","iopub.status.idle":"2024-10-16T13:52:24.914798Z","shell.execute_reply.started":"2024-10-16T13:40:53.439552Z","shell.execute_reply":"2024-10-16T13:52:24.913590Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"Making predictions: 100%|██████████| 782/782 [11:31<00:00,  1.13it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m         all_labels\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Convert lists to numpy arrays for easier processing\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m all_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray(all_predictions)\n\u001b[1;32m     21\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(all_labels)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"],"ename":"NameError","evalue":"name 'np' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import numpy as np\n\n# Convert lists to numpy arrays for easier processing\nall_predictions = np.array(all_predictions)\nall_labels = np.array(all_labels)\n\n# Calculate accuracy\naccuracy = (all_predictions == all_labels).mean()\nprint(f\"Test Accuracy: {accuracy:.4f}\")\n\n# More detailed metrics\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(all_labels, all_predictions))\n\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(all_labels, all_predictions))","metadata":{"execution":{"iopub.status.busy":"2024-10-16T13:57:57.562992Z","iopub.execute_input":"2024-10-16T13:57:57.563692Z","iopub.status.idle":"2024-10-16T13:57:58.064080Z","shell.execute_reply.started":"2024-10-16T13:57:57.563652Z","shell.execute_reply":"2024-10-16T13:57:58.063092Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Test Accuracy: 0.9364\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.93      0.95      0.94     12500\n           1       0.95      0.92      0.94     12500\n\n    accuracy                           0.94     25000\n   macro avg       0.94      0.94      0.94     25000\nweighted avg       0.94      0.94      0.94     25000\n\n\nConfusion Matrix:\n[[11849   651]\n [  940 11560]]\n","output_type":"stream"}]}]}
